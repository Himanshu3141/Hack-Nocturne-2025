{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 156 entries, body to username\n",
      "dtypes: float64(20), object(136)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                                                 body categories/0  \\\n",
       " 0                                                NaN          new   \n",
       " 1  I'm sure many people here would have seen the ...          NaN   \n",
       " 2  I actually value Apple's approach to making ev...          NaN   \n",
       " 3  There will never be decent AI on any of these ...          NaN   \n",
       " 4  There are better and better , tinier and tinie...          NaN   \n",
       " \n",
       "           categories/1 category communityName                 createdAt  \\\n",
       " 0  ?include_over_18=on      NaN           NaN  2008-01-25T03:43:06.000Z   \n",
       " 1                  NaN      NaN       r/apple  2025-03-27T18:54:22.000Z   \n",
       " 2                  NaN    apple       r/apple  2025-03-28T12:33:58.000Z   \n",
       " 3                  NaN    apple       r/apple  2025-03-28T13:48:10.000Z   \n",
       " 4                  NaN    apple       r/apple  2025-03-28T15:25:45.000Z   \n",
       " \n",
       "     dataType                                        description displayName  \\\n",
       " 0  community  An unofficial community about Apple and all of...       apple   \n",
       " 1       post                                                NaN         NaN   \n",
       " 2    comment                                                NaN         NaN   \n",
       " 3    comment                                                NaN         NaN   \n",
       " 4    comment                                                NaN         NaN   \n",
       " \n",
       "                  flair  ...         rules/12/shortName  \\\n",
       " 0                  NaN  ...  No vaccine misinformation   \n",
       " 1  Apple Intelligence   ...                        NaN   \n",
       " 2                  NaN  ...                        NaN   \n",
       " 3                  NaN  ...                        NaN   \n",
       " 4                  NaN  ...                        NaN   \n",
       " \n",
       "     rules/12/violationReason                 scrapedAt thumbnailUrl  \\\n",
       " 0  No vaccine misinformation  2025-03-28T19:27:35.987Z          NaN   \n",
       " 1                        NaN  2025-03-28T19:27:42.481Z         self   \n",
       " 2                        NaN  2025-03-28T19:27:42.580Z          NaN   \n",
       " 3                        NaN  2025-03-28T19:27:42.580Z          NaN   \n",
       " 4                        NaN  2025-03-28T19:27:42.580Z          NaN   \n",
       " \n",
       "                                                title upVoteRatio upVotes  \\\n",
       " 0                r/Apple: Unofficial Apple Community         NaN     NaN   \n",
       " 1  OpenAI's new image generation model is what Ge...        0.34     0.0   \n",
       " 2                                                NaN         NaN    12.0   \n",
       " 3                                                NaN         NaN     2.0   \n",
       " 4                                                NaN         NaN     1.0   \n",
       " \n",
       "                                                  url       userId  \\\n",
       " 0                    https://www.reddit.com/r/apple/          NaN   \n",
       " 1  https://www.reddit.com/r/apple/comments/1jlbjw...     t2_hiq6k   \n",
       " 2  https://www.reddit.com/r/apple/comments/1jlbjw...     t2_jn2jn   \n",
       " 3  https://www.reddit.com/r/apple/comments/1jlbjw...  t2_58z2axyd   \n",
       " 4  https://www.reddit.com/r/apple/comments/1jlbjw...  t2_1952rrde   \n",
       " \n",
       "           username  \n",
       " 0              NaN  \n",
       " 1         krikrija  \n",
       " 2  precipiceblades  \n",
       " 3   sherbert-stock  \n",
       " 4       MrBread134  \n",
       " \n",
       " [5 rows x 156 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"dataset_reddit-scraper-task_2025-03-28_19-30-24-130.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic info and first few rows\n",
    "df.info(), df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   body           1000 non-null   object             \n",
      " 1   title          1000 non-null   object             \n",
      " 2   communityName  1000 non-null   object             \n",
      " 3   createdAt      1000 non-null   datetime64[ns, UTC]\n",
      " 4   dataType       1000 non-null   object             \n",
      " 5   upVotes        1000 non-null   int64              \n",
      " 6   upVoteRatio    1000 non-null   float64            \n",
      " 7   url            1000 non-null   object             \n",
      " 8   username       1000 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(1), object(6)\n",
      "memory usage: 70.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                                                 body  \\\n",
       " 0                                                      \n",
       " 1  I'm sure many people here would have seen the ...   \n",
       " 2  I actually value Apple's approach to making ev...   \n",
       " 3  There will never be decent AI on any of these ...   \n",
       " 4  There are better and better , tinier and tinie...   \n",
       " \n",
       "                                                title communityName  \\\n",
       " 0                r/Apple: Unofficial Apple Community                 \n",
       " 1  OpenAI's new image generation model is what Ge...       r/apple   \n",
       " 2                                                          r/apple   \n",
       " 3                                                          r/apple   \n",
       " 4                                                          r/apple   \n",
       " \n",
       "                   createdAt   dataType  upVotes  upVoteRatio  \\\n",
       " 0 2008-01-25 03:43:06+00:00  community        0         0.00   \n",
       " 1 2025-03-27 18:54:22+00:00       post        0         0.34   \n",
       " 2 2025-03-28 12:33:58+00:00    comment       12         0.00   \n",
       " 3 2025-03-28 13:48:10+00:00    comment        2         0.00   \n",
       " 4 2025-03-28 15:25:45+00:00    comment        1         0.00   \n",
       " \n",
       "                                                  url         username  \n",
       " 0                    https://www.reddit.com/r/apple/          Unknown  \n",
       " 1  https://www.reddit.com/r/apple/comments/1jlbjw...         krikrija  \n",
       " 2  https://www.reddit.com/r/apple/comments/1jlbjw...  precipiceblades  \n",
       " 3  https://www.reddit.com/r/apple/comments/1jlbjw...   sherbert-stock  \n",
       " 4  https://www.reddit.com/r/apple/comments/1jlbjw...       MrBread134  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting relevant columns\n",
    "columns_to_keep = [\n",
    "    \"body\", \"title\", \"communityName\", \"createdAt\", \"dataType\", \"upVotes\", \n",
    "    \"upVoteRatio\", \"url\", \"username\"\n",
    "]\n",
    "df_cleaned = df[columns_to_keep].copy()\n",
    "\n",
    "# Convert createdAt to datetime\n",
    "df_cleaned[\"createdAt\"] = pd.to_datetime(df_cleaned[\"createdAt\"], errors=\"coerce\")\n",
    "\n",
    "df_cleaned[\"upVotes\"] = pd.to_numeric(df_cleaned[\"upVotes\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df_cleaned[\"upVoteRatio\"] = pd.to_numeric(df_cleaned[\"upVoteRatio\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Filling missing values in text columns with empty strings\n",
    "df_cleaned[\"body\"] = df_cleaned[\"body\"].fillna(\"\")\n",
    "df_cleaned[\"title\"] = df_cleaned[\"title\"].fillna(\"\")\n",
    "df_cleaned[\"communityName\"] = df_cleaned[\"communityName\"].fillna(\"\")\n",
    "df_cleaned[\"username\"] = df_cleaned[\"username\"].fillna(\"Unknown\")\n",
    "\n",
    "# Display the cleaned dataset info and first few rows\n",
    "df_cleaned.info(), df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "      <th>communityName</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>dataType</th>\n",
       "      <th>upVotes</th>\n",
       "      <th>upVoteRatio</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>r/Apple: Unofficial Apple Community</td>\n",
       "      <td></td>\n",
       "      <td>2008-01-25 03:43:06+00:00</td>\n",
       "      <td>community</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm sure many people here would have seen the ...</td>\n",
       "      <td>OpenAI's new image generation model is what Ge...</td>\n",
       "      <td>r/apple</td>\n",
       "      <td>2025-03-27 18:54:22+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>krikrija</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I actually value Apple's approach to making ev...</td>\n",
       "      <td></td>\n",
       "      <td>r/apple</td>\n",
       "      <td>2025-03-28 12:33:58+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>precipiceblades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There will never be decent AI on any of these ...</td>\n",
       "      <td></td>\n",
       "      <td>r/apple</td>\n",
       "      <td>2025-03-28 13:48:10+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>sherbert-stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are better and better , tinier and tinie...</td>\n",
       "      <td></td>\n",
       "      <td>r/apple</td>\n",
       "      <td>2025-03-28 15:25:45+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>MrBread134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0                                                      \n",
       "1  I'm sure many people here would have seen the ...   \n",
       "2  I actually value Apple's approach to making ev...   \n",
       "3  There will never be decent AI on any of these ...   \n",
       "4  There are better and better , tinier and tinie...   \n",
       "\n",
       "                                               title communityName  \\\n",
       "0                r/Apple: Unofficial Apple Community                 \n",
       "1  OpenAI's new image generation model is what Ge...       r/apple   \n",
       "2                                                          r/apple   \n",
       "3                                                          r/apple   \n",
       "4                                                          r/apple   \n",
       "\n",
       "                  createdAt   dataType  upVotes  upVoteRatio         username  \n",
       "0 2008-01-25 03:43:06+00:00  community        0         0.00                   \n",
       "1 2025-03-27 18:54:22+00:00       post        0         0.34         krikrija  \n",
       "2 2025-03-28 12:33:58+00:00    comment       12         0.00  precipiceblades  \n",
       "3 2025-03-28 13:48:10+00:00    comment        2         0.00   sherbert-stock  \n",
       "4 2025-03-28 15:25:45+00:00    comment        1         0.00       MrBread134  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_reddit-scraper-task_2025-03-28_19-30-24-130.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Keep only relevant columns\n",
    "columns_to_keep = [\"body\", \"title\", \"communityName\", \"createdAt\", \"dataType\", \"upVotes\", \"upVoteRatio\", \"username\"]\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Convert createdAt to datetime format\n",
    "df[\"createdAt\"] = pd.to_datetime(df[\"createdAt\"], errors=\"coerce\")\n",
    "\n",
    "# Convert numerical columns\n",
    "df[\"upVotes\"] = pd.to_numeric(df[\"upVotes\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"upVoteRatio\"] = pd.to_numeric(df[\"upVoteRatio\"], errors=\"coerce\").fillna(0.0).astype(float)\n",
    "\n",
    "# Fill missing text values with empty strings\n",
    "text_columns = [\"body\", \"title\", \"communityName\", \"username\"]\n",
    "df[text_columns] = df[text_columns].fillna(\"\")\n",
    "\n",
    "# Remove URLs from 'body' and 'title'\n",
    "url_pattern = r\"http[s]?://\\S+\"\n",
    "df[\"body\"] = df[\"body\"].apply(lambda x: re.sub(url_pattern, \"\", x))\n",
    "df[\"title\"] = df[\"title\"].apply(lambda x: re.sub(url_pattern, \"\", x))\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_file_path = \"cleaned_reddit_dataset.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Display sample rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 36 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n36 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 658, in fit\n    X, y = validate_data(\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1387, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1397, in _check_y\n    y = check_array(\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input y contains NaN.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 89\u001b[0m\n\u001b[0;32m     82\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m],\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor__learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m]\n\u001b[0;32m     86\u001b[0m }\n\u001b[0;32m     88\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Get best model\u001b[39;00m\n\u001b[0;32m     92\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32md:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    999\u001b[0m     )\n\u001b[1;32m-> 1001\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32md:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 36 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n36 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 658, in fit\n    X, y = validate_data(\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1387, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1397, in _check_y\n    y = check_array(\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"d:\\Hack-Nocturne-2025\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input y contains NaN.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"dataset_reddit-scraper-task_2025-03-28_19-30-24-130.csv\")\n",
    "\n",
    "# Drop rows with NaN in target variable\n",
    "df = df.dropna(subset=[\"upVotes\"])\n",
    "\n",
    "# Handle missing values\n",
    "df['body'] = df['body'].fillna('')\n",
    "df['imageUrls/0'] = df['imageUrls/0'].fillna('')\n",
    "df['createdAt'] = pd.to_datetime(df['createdAt'])\n",
    "\n",
    "# Extract datetime features\n",
    "df['hour_of_day'] = df['createdAt'].dt.hour\n",
    "df['day_of_week'] = df['createdAt'].dt.dayofweek\n",
    "\n",
    "# Derived features\n",
    "df[\"has_image\"] = df[\"imageUrls/0\"].apply(lambda x: 1 if x != '' else 0)\n",
    "df['text_length'] = df['body'].apply(len)\n",
    "\n",
    "# Cyclical encoding for time features\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour_of_day'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour_of_day'] / 24)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "# Sentiment analysis with error handling\n",
    "def get_sentiment(text):\n",
    "    try:\n",
    "        return TextBlob(str(text)).sentiment.polarity\n",
    "    except:\n",
    "        return 0  # Neutral sentiment for errors\n",
    "\n",
    "df['sentiment'] = df['body'].apply(get_sentiment)\n",
    "\n",
    "# Outlier removal (removing top 1% of upvotes)\n",
    "upper_bound = df[\"upVotes\"].quantile(0.99)\n",
    "df = df[df[\"upVotes\"] <= upper_bound]\n",
    "\n",
    "# Log-transform the target variable to reduce variance\n",
    "df[\"log_upVotes\"] = np.log1p(df[\"upVotes\"])  # log(1 + upVotes) avoids log(0)\n",
    "y = df[\"log_upVotes\"]\n",
    "\n",
    "# Mean encoding for subreddit (communityName)\n",
    "subreddit_avg_upvotes = df.groupby(\"communityName\")[\"upVotes\"].mean()\n",
    "df[\"community_mean_upvotes\"] = df[\"communityName\"].map(subreddit_avg_upvotes)\n",
    "\n",
    "# Define features\n",
    "X = df[[\"body\", \"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\", \n",
    "        \"has_image\", \"text_length\", \"sentiment\", \"community_mean_upvotes\"]]\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", TfidfVectorizer(max_features=500, stop_words='english'), \"body\"),  # Reduced TF-IDF features\n",
    "        (\"num\", StandardScaler(), [\"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\", \n",
    "                                   \"text_length\", \"sentiment\", \"community_mean_upvotes\"]),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Gradient Boosting Model Pipeline\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [200, 500],\n",
    "    'regressor__learning_rate': [0.05, 0.1],\n",
    "    'regressor__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Convert log predictions back to original scale\n",
    "predictions = np.expm1(predictions)  # Reverse log(1 + upVotes)\n",
    "\n",
    "# Convert true values back to original scale\n",
    "y_test_original = np.expm1(y_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test_original, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_original, predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_names = best_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "importances = best_model.named_steps['regressor'].feature_importances_\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "for name, importance in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{name}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
